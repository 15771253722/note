# 		Redis

## 一. redis是什么？

简述:

> Redis是一个完全免费开源的，基于内存的高性能key-value存储系统，可以用作数据库、缓存和消息中间件。支持多种类型的数据结构. Redis内置数据持久化、LRU驱动事件、事物、主从复制、哨兵机制、集群、自动分区、lua脚本提供高可用性.

特点:

- 速度快:使用标准c语言编写,所有数据在内存存储,读速度:110000次/s 写速度:81000次/s
- 基本数据类型(5种):string,list,hash,set,zset. 衍生数据类型:bitmaps,hyperloglogs,地理空间
- 原子性:redis本身所有操作都是原子性,同时还通过事物,非事物流水线(pipeline),和lua脚本,保证多条命令的原子性
- 持久化:支持RDB,AOF两种方式将内存数据持久化到本地磁盘
- 高可用:支持主从复制(master-slave),哨兵机制(sentinel),集群,分片
- 其他:键空间通知(发布订阅),消息队列

架构:

- 单线程:一次只能执行一条命令,拒绝长命令(因为Redis基于内存,不牵扯磁盘IO操作限制)
- 多路IO复用模型,非阻塞IO(单个线程监控多个流I/O事件,空闲时阻塞当前线程.如果有I/o事件,则轮询一遍所有的流)

## 二. 什么时候用？

使用场景

- 缓存: 配合关系型数据库做高速缓存(string)
- 计数器: 用户点赞,评论数,投票,网站访问量,点击率等(string)
- 分布式锁: 分布式环境下,访问共享资源(string)
- 分布式session: 分布式环境下,需要session共享(string)
- 用户信息,发布文章信息等(hash)
- 朋友圈,微博时间线,自动补全联系人(list)
- 抽奖系统,给用户添加标签,给标签添加用户、共同关注
- 排行榜(zset)
- GEO(计算两地距离,外卖小哥距你还有多少米)

## 三. 为什么要用？

主流NoSQL对比

- 性能
  都比较高，性能对我们来说应该都不是瓶颈
  总体来讲，TPS方面redis和memcache差不多，要大于mongodb
- 操作的便利性
  memcache 数据结构单一
  redis 丰富一些，数据操作方面，redis更好一些，较少的网络IO次数
  mongodb 支持丰富的数据表达，索引，最类似关系型数据库，支持的查询语言非常丰富
- 内存空间的大小和数据量的大小
  redis 在2.0版本后增加了自己的VM特性，突破物理内存的限制；可以对key value设置过期时间（类似memcache）
  memcache 可以修改最大可用内存,采用LRU算法
  mongoDB 适合大数据量的存储，依赖操作系统VM做内存管理，吃内存也比较厉害，服务不要和别的服务在一起
- 可用性（单点问题）
  对于单点问题
  redis 依赖客户端来实现分布式读写；主从复制时，每次从节点重新连接主节点都要依赖整个快照,无增量复制，因性能和效率问题，
  所以单点问题比较复杂；不支持自动sharding,需要依赖程序设定一致hash 机制。
  一种替代方案是，不用redis本身的复制机制，采用自己做主动复制（多份存储），或者改成增量复制的方式（需要自己实现），一致性问题和性能的权衡
  Memcache 本身没有数据冗余机制，也没必要；对于故障预防，采用依赖成熟的hash或者环状的算法，解决单点故障引起的抖动问题。
  mongoDB 支持master-slave,replicaset（内部采用paxos选举算法，自动故障恢复）,auto sharding机制，对客户端屏蔽了故障转移和切分机制。
- 可靠性（持久化）
  对于数据持久化和数据恢复，
  redis 支持（快照、AOF）：依赖快照进行持久化，aof增强了可靠性的同时，对性能有所影响
  memcache 不支持，通常用在做缓存,提升性能；
  MongoDB 从1.8版本开始采用binlog方式支持持久化的可靠性
- 数据一致性（事务支持）
  Memcache 在并发场景下，用cas保证一致性
  redis 事务支持比较弱，只能保证事务中的每个操作连续执行
  mongoDB 不支持事务
- 数据分析
  mongoDB 内置了数据分析的功能(mapreduce),其他不支持
- 应用场景
  redis 数据量较小的更性能操作和运算上
  memcache 用于在动态系统中减少数据库负载，提升性能;做缓存，提高性能（适合读多写少，对于数据量比较大，可以采用sharding）
  MongoDB 主要解决海量数据的访问效率问题

## 四. 怎么用

五种数据类型常用命令:

​    1. string类型

```java
set key value # 设置指定key的值
get key      # 获取指定key的值
del key      # 删除指定key的值
incr key     # key自增1，如果key不存在，自增后get(key)=1
decr key     # key自减1，如果key不存在，自减后get(key)=-1
incrby key k # key自增k，如果key不存在，自增后get(key)=k
decrby key k # key自减k，如果key不存在，自减后get(key)=-k
set key value # 不管key是否存在，都设置
setnx key value # key不存在，才设置
set key value xx # key存在，才设置
mget key1 key2 key3 # 批量获取key，原子操作
mset key1 value1 key2 value2 # 批量设置key-value
getset key newvalue # set key newvalue并返回旧的value
append key value # 将value追加到旧的value
```

​    2. hash类型

```java
hget key field    # 获取hash key对应的field的value
hset key field value # 设置hash key对应field的value
hdel key field  # 删除hash key对应field的value
hexists key field # 判断hash key是否有field
hlen key # 获取hash key field的数量
hmget key field1 field2 ... fieldN # 批量获取hash key的一批field对应的值
hmset key field1 value1 field2 value2 ... fieldN valueN # 批量设置hash key的一批field value
hgetall key # 返回hash key对应所有的field和value
hvals key   # 返回hash key对应所有filed的value
hkeys key   # 返回hash key对应所有field
```

​    3. list类型

```java
rpush key value1 value2 ... valueN # 从列表右端插入值
lpush key value1 value2 ... valueN # 从列表左端插入值
linsert key before|after value newValue # 在list指定的值前|后插入newValue
lpop key # 从列表左侧弹出一个item
rpop    # 从列表右侧弹出一个item
lrem key count value    
 # 根据count值，从列表中删除所有value相等的项
 #（1）count>0，从左到右，删除最多count个value相等的项
 # (2)count<0，从右到左，删除最多Math.abs(count)个value相等项
 # (3)count=0，删除所有value相等的项
ltrim key start end # 按照索引范围修剪列表
lrange key start end(包含end) # 获取列表指定索引范围所有item
lindex key index # 获取列表指定索引的item
llen key # 获取列表长度
lset key index newValue # 设置列表指定索引值为newValue
blpop key timeout # lpop阻塞版本，timeout是阻塞超时时间
brpop key timeout # rpop阻塞版本，timeout是阻塞超时时间 
    #（如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止）
         
扩展应用：
    1、LRUSH + LPOP = Stack  栈：先进后出
    2、LPUSH + RPOP = Queue  队列：先进先出
    3、LPUSH + BRPOP = Message Queue  消息队列
```

​    4. set类型

```java
sadd key element  # 向集合key添加element
                 # 如果element已经存在，添加失败
srem key element  # 将集合key中的element移除掉
scard key # 计算集合大小
sismember key element # 判断element是否在集合中
srandmember key count # 从集合中随机挑选count个元素
spop key # 从集合中随机弹出一个元素
smove source-key dest-key item #将元素item从source-key移除添加进dest-key
smembers key # 获取集合所有元素
sdiff key1 key2  # 差集
sdiffstore dest-key key-name # 差集结果存入新集合
sinter key1 key2 # 交集
sinterstore dest-key key-name # 交集结果存入新集合
sunion key1 key2 # 并集
sunionstore dest-key key-name # 并差集结果存入新集合
```

​    5. zset类型

```java
zadd key score element（可以是多对）# 添加score和element
zrem key element（可以是多个） # 删除元素
zscore key element # 返回元素的分数
zcount key min max # 返回分值介于min和max之间的成员数量
zincrby key increScore element # 增加或减少元素的分数
zcard key # 返回元素的总个数
zrange key start end  s# 返回指定索引范围内的升序元素【分值】
zrangebyscore key minScore maxScore  # 返回指定分数范围内的升序元素【分值】
zremrangebyrank key start end  # 删除指定排名内的升序元素
zremrangebyscore key minScore maxScore # 删除指定分数内的升序元素
```

## 五.事务

**Redis事务的概念：**

　　Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。

　　总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。　　

**Redis事务没有隔离级别的概念：**

　　批量操作在发送 EXEC 命令前被放入队列缓存，并不会被实际执行，也就不存在事务内的查询要看到事务里的更新，事务外查询不能看到。

**Redis不保证原子性：**

　　Redis中，单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令仍会被执行。

**Redis事务的三个阶段：**

- 开始事务
- 命令入队
- 执行事务

**Redis事务相关命令：**

　　watch key1 key2 ... : 监视一或多个key,如果在事务执行之前，被监视的key被其他命令改动，则事务被打断 （ 类似乐观锁 ）

　　multi : 标记一个事务块的开始（ queued ）

　　exec : 执行所有事务块的命令 （ 一旦执行exec后，之前加的监控锁都会被取消掉 ）　

　　discard : 取消事务，放弃事务块中的所有命令

　　unwatch : 取消watch对所有key的监控

 **总结：**

　　watch指令类似于乐观锁，在事务提交时，如果watch监控的多个KEY中任何KEY的值已经被其他客户端更改，则使用EXEC执行事务时，事务队列将不会被执行，同时返回Nullmulti-bulk应答以通知调用者事务执行失败。

## 六.管道

Redis客户端与服务器之间使用TCP协议进行通信，并且很早就支持管道（pipelining）技术了。在某些高并发的场景下，网络开销成了Redis速度的瓶颈，所以需要使用管道技术来实现突破。

在介绍管道之前，先来想一下单条命令的执行步骤：

- 客户端把命令发送到服务器，然后阻塞客户端，等待着从socket读取服务器的返回结果
- 服务器处理命令并将结果返回给客户端

按照这样的描述，每个**命令的执行时间 = 客户端发送时间+服务器处理和返回时间+一个网络来回的时间**

其中一个网络来回的时间是不固定的，它的决定因素有很多，比如客户端到服务器要经过多少跳，网络是否拥堵等等。但是这个时间的量级也是最大的，也就是说一个命令的完成时间的长度很大程度上取决于网络开销。如果我们的服务器每秒可以处理10万条请求，而网络开销是250毫秒，那么实际上每秒钟只能处理4个请求。最暴力的优化方法就是使客户端和服务器在一台物理机上，这样就可以将网络开销降低到1ms以下。但是实际的生产环境我们并不会这样做。而且即使使用这种方法，当请求非常频繁时，这个时间和服务器处理时间比较仍然是很长的。

### Redis Pipelining

为了解决这种问题，Redis在很早就支持了管道技术。也就是说客户端可以一次发送多条命令，不用逐条等待命令的返回值，而是到最后一起读取返回结果，这样只需要一次网络开销，速度就会得到明显的提升。管道技术其实已经非常成熟并且得到广泛应用了，例如POP3协议由于支持管道技术，从而显著提高了从服务器下载邮件的速度。

在Redis中，如果客户端使用管道发送了多条命令，那么服务器就会将多条命令放入一个队列中，这一操作会消耗一定的内存，所以**管道中命令的数量并不是越大越好**（太大容易撑爆内存），而是应该有一个合理的值。

### 总结

1. 使用管道技术可以显著提升Redis处理命令的速度，其原理就是将多条命令打包，只需要一次网络开销，在服务器端和客户端各一次`read()`和`write()`系统调用，以此来节约时间。
2. 管道中的命令数量要适当，并不是越多越好。
3. Redis2.6版本以后，脚本在大部分场景中的表现要优于管道。

## 七.持久化

#### 1、前言

Redis是一种高级key-value数据库。它跟memcached类似，不过数据可以持久化，而且支持的数据类型很丰富。有字符串，链表，集 合和有序集合。支持在服务器端计算集合的并，交和补集(difference)等，还支持多种排序功能。所以Redis也可以被看成是一个数据结构服务 器。
Redis的所有数据都是保存在内存中，然后不定期的通过异步方式保存到磁盘上(这称为“半持久化模式”)；也可以把每一次数据变化都写入到一个append only file(aof)里面(这称为“全持久化模式”)。 

由于Redis的数据都存放在内存中，如果没有配置持久化，redis重启后数据就全丢失了，于是需要开启redis的持久化功能，将数据保存到磁盘上，当redis重启后，可以从磁盘中恢复数据。redis提供两种方式进行持久化，一种是RDB持久化（原理是将Reids在内存中的数据库记录定时dump到磁盘上的RDB持久化），另外一种是AOF（append only file）持久化（原理是将Reids的操作日志以追加的方式写入文件）。那么这两种持久化方式有什么区别呢，改如何选择呢？网上看了大多数都是介绍这两种方式怎么配置，怎么使用，就是没有介绍二者的区别，在什么应用场景下使用。

#### 2、二者的区别

RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。

![img](https://images2017.cnblogs.com/blog/388326/201707/388326-20170726161552843-904424952.png)

 

AOF持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。

![img](https://images2017.cnblogs.com/blog/388326/201707/388326-20170726161604968-371688235.png)

 

#### 3、二者优缺点

#### RDB存在哪些优势呢？

1). 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。

2). 对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。

3). 性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。

4). 相比于AOF机制，如果数据集很大，RDB的启动效率会更高。

RDB又存在哪些劣势呢？

1). 如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。

2). 由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。

#### AOF的优势有哪些呢？

1). 该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于无同步，无需多言，我想大家都能正确的理解它。

2). 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。

3). 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。

4). AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。

AOF的劣势有哪些呢？

1). 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。

2). 根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和RDB一样高效。

二者选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行save的时候，再做备份（rdb）。rdb这个就更有些 eventually consistent的意思了。

#### 4、常用配置

#### RDB持久化配置

Redis会将数据集的快照dump到dump.rdb文件中。此外，我们也可以通过配置文件来修改Redis服务器dump快照的频率，在打开6379.conf文件之后，我们搜索save，可以看到下面的配置信息：

save 900 1              #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。

save 300 10            #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。

save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。

#### AOF持久化配置

在Redis的配置文件中存在三种同步方式，它们分别是：

appendfsync always     #每次有数据修改发生时都会写入AOF文件。

appendfsync everysec  #每秒钟同步一次，该策略为AOF的缺省策略。

appendfsync no          #从不同步。高效但是数据不会被持久化。

## 八.集群

## 1.1        集群的概念

所谓的集群，就是通过添加服务器的数量，提供相同的服务，从而让服务器达到一个稳定、高效的状态。

### 1.1.1       使用redis集群的必要性

问题：我们已经部署好了redis，并且能启动一个redis，实现数据的读写，为什么还要学习redis集群？

答：（1）单个redis存在不稳定性。当redis服务宕机了，就没有可用的服务了。

（2）单个redis的读写能力是有限的。

**总结：redis****集群是为了强化redis****的读写能力。**

### 1.1.2       如何学习redis集群

--说明：（1）redis集群中，每一个redis称之为一个节点。

​      （2）redis集群中，有两种类型的节点：主节点(master)、从节点(slave)。

​      （3）redis集群，是基于redis主从复制实现。

​                         

所以，学习redis集群，就是从学习redis主从复制模型开始的。

#### 主从复制

#### 哨兵模式